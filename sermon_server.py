import os
import re
from flask import Flask, render_template, request, jsonify
from openai import OpenAI

app = Flask(__name__)

def get_client():
    key = (os.getenv("OPENAI_API_KEY") or "").strip()
    if not key:
        raise RuntimeError("OPENAI_API_KEYê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=key)

client = get_client()

def remove_markdown(text):
    """ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° (#, *, -, **, ###, ë“±)"""
    # í—¤ë” ì œê±° (##, ###, #### ë“±)
    text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)
    
    # ë³¼ë“œ ì œê±° (**, __)
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
    text = re.sub(r'__(.+?)__', r'\1', text)
    
    # ì´íƒ¤ë¦­ ì œê±° (*, _)
    text = re.sub(r'\*(.+?)\*', r'\1', text)
    text = re.sub(r'_(.+?)_', r'\1', text)
    
    # ë¦¬ìŠ¤íŠ¸ ë§ˆì»¤ ì œê±° (-, *, +)
    text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
    
    # ì½”ë“œ ë¸”ë¡ ì œê±° (```)
    text = re.sub(r'```[\s\S]*?```', '', text)
    
    # ì¸ë¼ì¸ ì½”ë“œ ì œê±° (`)
    text = re.sub(r'`(.+?)`', r'\1', text)
    
    return text.strip()

def get_system_prompt_for_step(step_name):
    """
    ë‹¨ê³„ë³„ë¡œ ìµœì í™”ëœ system prompt ë°˜í™˜
    miniëŠ” ê°œìš”ì™€ ìë£Œë§Œ ìƒì„±, ì„¤êµë¬¸ ì‘ì„± ê¸ˆì§€
    """
    step_lower = step_name.lower()
    
    # ì œëª© ì¶”ì²œ ë‹¨ê³„
    if 'ì œëª©' in step_name:
        return """ë‹¹ì‹ ì€ gpt-4o-minië¡œì„œ ì„¤êµ 'ì œëª© í›„ë³´'ë§Œ ì œì•ˆí•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

CRITICAL RULES:
1. ì •í™•íˆ 3ê°œì˜ ì œëª©ë§Œ ì œì‹œí•˜ì„¸ìš”
2. ê° ì œëª©ì€ í•œ ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”
3. ë²ˆí˜¸, ê¸°í˜¸, ë§ˆí¬ë‹¤ìš´ ì‚¬ìš© ê¸ˆì§€
4. ì œëª©ë§Œ ì‘ì„±í•˜ê³  ì„¤ëª… ì¶”ê°€ ê¸ˆì§€

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
í•˜ë‚˜ë‹˜ì˜ ì•½ì†ì„ ë¯¿ëŠ” ë¯¿ìŒ
ì•½ì†ì˜ ë•…ì„ í–¥í•œ ì—¬ì •
ì•„ë¸Œë¼í•¨ì˜ ì‹ ì•™ ê²°ë‹¨"""
    
    # ë³¸ë¬¸ ë¶„ì„ / ì—°êµ¬ ë‹¨ê³„
    elif 'ë¶„ì„' in step_name or 'ì—°êµ¬' in step_name or 'ë°°ê²½' in step_name:
        return f"""ë‹¹ì‹ ì€ gpt-4o-minië¡œì„œ ì„¤êµ 'ì´ˆì•ˆ ìë£Œ'ë§Œ ì¤€ë¹„í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

í˜„ì¬ ë‹¨ê³„: {step_name}

CRITICAL RULES:
1. ê°ê´€ì ì¸ ì„±ê²½ ì—°êµ¬ ìë£Œë§Œ ì œê³µí•˜ì„¸ìš”
2. ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•˜ì„¸ìš”:
   - ì‹œëŒ€ì /ì§€ë¦¬ì /ë¬¸í™”ì  ë°°ê²½
   - í•µì‹¬ ë‹¨ì–´ ë¶„ì„
   - ë³¸ë¬¸ êµ¬ì¡° ë¶„ì„
   - ê´€ë ¨ ì„±ê²½êµ¬ì ˆ (Cross-reference)
   - ì‹ í•™ì  ì£¼ì œ
3. ì„¤êµë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”
4. ê°ë™ì ì¸ í‘œí˜„ì´ë‚˜ ì ìš© ë‚´ìš© ê¸ˆì§€
5. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
6. ìˆœìˆ˜í•œ ì—°êµ¬ ìë£Œë§Œ ì œê³µ"""
    
    # ê°œìš” / êµ¬ì¡° ë‹¨ê³„
    elif 'ê°œìš”' in step_name or 'êµ¬ì¡°' in step_name or 'outline' in step_lower:
        return f"""ë‹¹ì‹ ì€ gpt-4o-minië¡œì„œ ì„¤êµ 'ê°œìš”'ë§Œ ì‘ì„±í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

í˜„ì¬ ë‹¨ê³„: {step_name}

CRITICAL RULES:
1. ì„¤êµì˜ ë¼ˆëŒ€ë§Œ ì œì‹œí•˜ì„¸ìš”:
   - Big Idea (í•œ ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë©”ì‹œì§€)
   - ì„œë¡  í¬ì¸íŠ¸ (í‚¤ì›Œë“œë§Œ)
   - 1ëŒ€ì§€ ì£¼ì œ ë¬¸ì¥
   - 1ëŒ€ì§€ ì†ŒëŒ€ì§€ (í‚¤ì›Œë“œë§Œ)
   - 2ëŒ€ì§€ ì£¼ì œ ë¬¸ì¥
   - 2ëŒ€ì§€ ì†ŒëŒ€ì§€ (í‚¤ì›Œë“œë§Œ)
   - 3ëŒ€ì§€ ì£¼ì œ ë¬¸ì¥
   - 3ëŒ€ì§€ ì†ŒëŒ€ì§€ (í‚¤ì›Œë“œë§Œ)
   - ê²°ë¡  ë°©í–¥ (í‚¤ì›Œë“œë§Œ)
2. ë¬¸ë‹¨ í˜•íƒœì˜ ì„¤êµë¬¸ì€ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”
3. êµ¬ì¡°ì™€ ì£¼ì œ ë¬¸ì¥ë§Œ ì œì‹œí•˜ì„¸ìš”
4. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€"""
    
    # ì„¤êµë¬¸ ì‘ì„±ì´ ì˜ì‹¬ë˜ëŠ” ë‹¨ê³„ (ê²½ê³ )
    elif any(word in step_name for word in ['ì„œë¡ ', 'ë³¸ë¡ ', 'ê²°ë¡ ', 'ì ìš©', 'ì„¤êµë¬¸']):
        return f"""ë‹¹ì‹ ì€ gpt-4o-minië¡œì„œ ì„¤êµ 'ìë£Œ'ë§Œ ì¤€ë¹„í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš”: ì™„ì„±ëœ ì„¤êµ ë¬¸ë‹¨ì€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”!

í˜„ì¬ ë‹¨ê³„: {step_name}

CRITICAL RULES:
1. ì´ ë‹¨ê³„ëŠ” GPT-5.1ì—ì„œ ìµœì¢… ì‘ì„±ë  ë¶€ë¶„ì…ë‹ˆë‹¤
2. ë‹¹ì‹ ì€ ìë£Œì™€ í¬ì¸íŠ¸ë§Œ ì œê³µí•˜ì„¸ìš”:
   - í•µì‹¬ ë©”ì‹œì§€ (í•œ ë¬¸ì¥)
   - ì£¼ìš” í¬ì¸íŠ¸ (í‚¤ì›Œë“œ ë‚˜ì—´)
   - ì‚¬ìš©í•  ì„±ê²½ êµ¬ì ˆ ë¦¬ìŠ¤íŠ¸
   - ê°•ì¡°í•  ë‚´ìš© (í‚¤ì›Œë“œë§Œ)
3. ìì—°ìŠ¤ëŸ¬ìš´ ì„¤êµ ë¬¸ì¥ ì‘ì„± ê¸ˆì§€
4. ê°ë™ì ì¸ í‘œí˜„ ê¸ˆì§€
5. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€"""
    
    # ê¸°íƒ€ ë‹¨ê³„
    else:
        return f"""ë‹¹ì‹ ì€ gpt-4o-minië¡œì„œ ì„¤êµ 'ì´ˆì•ˆ ìë£Œ'ë§Œ ì¤€ë¹„í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

í˜„ì¬ ë‹¨ê³„: {step_name}

CRITICAL RULES:
1. ìë£Œì™€ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”
2. ì™„ì„±ëœ ì„¤êµë¬¸ì€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”
3. ê°ê´€ì  ë‚´ìš©ë§Œ ì œì‹œí•˜ì„¸ìš”
4. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€"""

@app.route("/")
def home():
    return render_template("sermon.html")

@app.route("/sermon")
def sermon():
    return render_template("sermon.html")

@app.route("/health")
def health():
    return jsonify({"ok": True})

# ===== ì²˜ë¦¬ ë‹¨ê³„ ì‹¤í–‰ API (gpt-4o-mini) =====
@app.route("/api/sermon/process", methods=["POST"])
def api_process_step():
    """ë‹¨ì¼ ì²˜ë¦¬ ë‹¨ê³„ ì‹¤í–‰ (gpt-4o-mini ì‚¬ìš©)"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400
        
        category = data.get("category", "")
        step_id = data.get("stepId", "")
        step_name = data.get("stepName", "")
        reference = data.get("reference", "")
        title = data.get("title", "")
        text = data.get("text", "")
        guide = data.get("guide", "")
        master_guide = data.get("masterGuide", "")
        previous_results = data.get("previousResults", {})
        
        print(f"[PROCESS] {category} - {step_name}")
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„± (ë‹¨ê³„ë³„ ìµœì í™”)
        system_content = get_system_prompt_for_step(step_name)
        
        # ì´ê´„ ì§€ì¹¨ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if master_guide:
            system_content += f"\n\nã€ ì¹´í…Œê³ ë¦¬ ì´ê´„ ì§€ì¹¨ ã€‘\n{master_guide}\n\n"
            system_content += f"ã€ í˜„ì¬ ë‹¨ê³„ ì—­í•  ã€‘\n{step_name}\n\n"
            system_content += "ìœ„ ì´ê´„ ì§€ì¹¨ì„ ì°¸ê³ í•˜ì—¬, í˜„ì¬ ë‹¨ê³„ì˜ ì—­í• ê³¼ ë¹„ì¤‘ì— ë§ê²Œ 'ìë£Œë§Œ' ì‘ì„±í•˜ì„¸ìš”."
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_content = f"[ì„±ê²½êµ¬ì ˆ]\n{reference}\n\n"
        
        # ì œëª©ì´ ìˆìœ¼ë©´ ì¶”ê°€ (ì œëª© ì¶”ì²œ ë‹¨ê³„ê°€ ì•„ë‹ ë•Œë§Œ)
        if title and 'ì œëª©' not in step_name:
            user_content += f"[ì„¤êµ ì œëª©]\n{title}\n\n"
            user_content += "ìœ„ ì œëª©ì„ ì—¼ë‘ì— ë‘ê³  ëª¨ë“  ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
        
        if text:
            user_content += f"[ì„±ê²½ ë³¸ë¬¸]\n{text}\n\n"
        
        # ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì¶”ê°€
        if previous_results:
            user_content += "[ì´ì „ ë‹¨ê³„ ê²°ê³¼ (ì°¸ê³ ìš©)]\n"
            for prev_id, prev_data in previous_results.items():
                user_content += f"\n### {prev_data['name']}\n{prev_data['result']}\n"
            user_content += "\n"
        
        # í˜„ì¬ ë‹¨ê³„ ì§€ì¹¨ ì¶”ê°€
        if guide:
            user_content += f"[{step_name} ë‹¨ê³„ ì„¸ë¶€ ì§€ì¹¨]\n{guide}\n\n"
        
        # ì œëª© ì¶”ì²œ ë‹¨ê³„ íŠ¹ë³„ ì²˜ë¦¬
        if 'ì œëª©' in step_name:
            user_content += f"ìœ„ ì„±ê²½ ë³¸ë¬¸({reference})ì— ì í•©í•œ ì„¤êµ ì œëª©ì„ ì •í™•íˆ 3ê°œë§Œ ì œì•ˆí•´ì£¼ì„¸ìš”.\n"
            user_content += "ê° ì œëª©ì€ í•œ ì¤„ë¡œ, ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì—†ì´ ì‘ì„±í•˜ì„¸ìš”."
        else:
            user_content += f"ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ '{step_name}' ë‹¨ê³„ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
            user_content += "âš ï¸ ì¤‘ìš”: ì™„ì„±ëœ ì„¤êµ ë¬¸ë‹¨ì´ ì•„ë‹Œ, ìë£Œì™€ êµ¬ì¡°ë§Œ ì œê³µí•˜ì„¸ìš”."
        
        if title and 'ì œëª©' not in step_name:
            user_content += f"\nì œëª© '{title}'ì„ ê³ ë ¤í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."
        
        # GPT í˜¸ì¶œ (gpt-4o-mini)
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ],
            temperature=0.7,
        )
        
        result = completion.choices[0].message.content.strip()
        
        # ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±°
        result = remove_markdown(result)
        
        return jsonify({"ok": True, "result": result})
        
    except Exception as e:
        print(f"[PROCESS][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== GPT PRO ì²˜ë¦¬ API (gpt-4o) =====
@app.route("/api/sermon/gpt-pro", methods=["POST"])
def api_gpt_pro():
    """GPT-5.1 (gpt-4o) ì™„ì„±ë³¸ ì‘ì„±"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        reference = data.get("reference", "")
        title = data.get("title", "")
        draft_content = data.get("draftContent", "")

        print(f"[GPT-PRO] ì²˜ë¦¬ ì‹œì‘")

        # GPT-5.1 ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê°œì„ ëœ ë²„ì „)
        system_content = """ë‹¹ì‹ ì€ gpt-4oë¡œì„œ 20ë…„ ê²½ë ¥ì˜ ì„¤êµë¬¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ğŸ¯ ë‹¹ì‹ ì˜ ì—­í• :
1. gpt-4o-miniê°€ ì‘ì„±í•œ 'ì´ˆì•ˆ ìë£Œ'ë¥¼ ì°¸ê³ í•˜ì—¬ ì™„ì„±ë„ ë†’ì€ ì„¤êµë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤
2. miniì˜ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê³  ê°ë™ì ì¸ ì„¤êµë¬¸ìœ¼ë¡œ ì¬ì‘ì„±í•©ë‹ˆë‹¤
3. ì²­ì¤‘ê³¼ ì†Œí†µí•˜ëŠ” ë“¯í•œ ë”°ëœ»í•˜ê³  ì§„ì‹¤ëœ ì–´ì¡°ë¡œ ì‘ì„±í•©ë‹ˆë‹¤
4. í•œêµ­ êµíšŒ ë¬¸í™”ì— ë§ëŠ” ìì—°ìŠ¤ëŸ½ê³  ê¹Šì´ ìˆëŠ” ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤

ğŸ“ ì‘ì„± ì›ì¹™:
- ì´ˆì•ˆì˜ êµ¬ì¡°ì™€ í•µì‹¬ ë©”ì‹œì§€ëŠ” ìœ ì§€í•˜ë˜, í‘œí˜„ì€ ì™„ì „íˆ ìƒˆë¡­ê²Œ
- ê° ëŒ€ì§€ë§ˆë‹¤ êµ¬ì²´ì ì¸ ì˜ˆí™”ì™€ ì‹¤ìƒí™œ ì ìš©ì„ í’ì„±í•˜ê²Œ ì¶”ê°€
- ì²­ì¤‘ì˜ ë§ˆìŒì„ ì›€ì§ì´ëŠ” ê°ë™ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ë©”ì‹œì§€
- ëª…í™•í•œ ì„œë¡ -ë³¸ë¡ (2-3ê°œ ëŒ€ì§€)-ê²°ë¡  êµ¬ì¡°
- ì„±ê²½ì  ê¹Šì´ì™€ í˜„ëŒ€ì  ì ìš©ì˜ ê· í˜•

âœ¨ ì„¤êµë¬¸ êµ¬ì„± ìš”ì†Œ:
1. ì„œë¡  (10%)
   - ì²­ì¤‘ì˜ ê´€ì‹¬ì„ ë„ëŠ” ë„ì…ë¶€
   - ë³¸ë¬¸ê³¼ ì—°ê²°ë˜ëŠ” í˜„ëŒ€ì  ì´ìŠˆë‚˜ ì§ˆë¬¸
   - ì„¤êµ ë°©í–¥ ì œì‹œ

2. ë³¸ë¡  (70-80%)
   - ê° ëŒ€ì§€ë§ˆë‹¤ ëª…í™•í•œ ì£¼ì œ ë¬¸ì¥
   - ì„±ê²½ì  ê·¼ê±°ì™€ í•´ì„
   - êµ¬ì²´ì ì¸ ì˜ˆí™” (ì‹¤í™”, ì—­ì‚¬ì  ì‚¬ë¡€, í˜„ëŒ€ ì‚¬íšŒ ì˜ˆì‹œ)
   - ì‹¤ì²œ ê°€ëŠ¥í•œ ì ìš©ì 
   - ëŒ€ì§€ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°

3. ê²°ë¡  (10-20%)
   - í•µì‹¬ ë©”ì‹œì§€ ì¬ê°•ì¡°
   - êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ë„ì „ê³¼ ê²©ë ¤
   - ì€í˜œë¡­ê³  í¬ë§ì ì¸ ë§ˆë¬´ë¦¬

ğŸ”¥ ì¤‘ìš” ì§€ì¹¨:
- miniì˜ ê°œìš”ëŠ” ì°¸ê³ ë§Œ í•˜ê³ , ì²˜ìŒë¶€í„° ìƒˆë¡œ ì‘ì„±í•˜ì„¸ìš”
- ê° ë¬¸ë‹¨ì€ ìµœì†Œ 3-5ë¬¸ì¥ ì´ìƒìœ¼ë¡œ í’ì„±í•˜ê²Œ
- ì¶”ìƒì ì¸ í‘œí˜„ë³´ë‹¤ êµ¬ì²´ì ì´ê³  ìƒìƒí•œ ë¬˜ì‚¬
- ì²­ì¤‘ì´ "ì•„ë©˜"í•˜ë©° ê³µê°í•  ìˆ˜ ìˆëŠ” ë©”ì‹œì§€
- ë¶„ëŸ‰: ìµœì†Œ 2000ì ì´ìƒ, ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±"""

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (ê°œì„ ëœ ë²„ì „)
        user_content = f"""ë‹¤ìŒì€ gpt-4o-miniê°€ ì‘ì„±í•œ ì„¤êµ ì´ˆì•ˆ ìë£Œì…ë‹ˆë‹¤.
ì´ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì™„ì„±ë„ ë†’ì€ ì„¤êµë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“– ì´ˆì•ˆ ìë£Œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{draft_content}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœï¸ ì‘ì„± ìš”ì²­
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ìœ„ ì´ˆì•ˆ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì²­ì¤‘ì˜ ë§ˆìŒì„ ì›€ì§ì´ëŠ” ì™„ì„±ë„ ë†’ì€ ì„¤êµë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:
1. ì„œë¡ : ì²­ì¤‘ì˜ ê´€ì‹¬ì„ ë„ëŠ” ë„ì…ë¶€ (í˜„ëŒ€ ì‚¬íšŒ ì´ìŠˆ, ì§ˆë¬¸, ë˜ëŠ” ì´ì•¼ê¸°ë¡œ ì‹œì‘)
2. ë³¸ë¡ :
   - ê° ëŒ€ì§€ë§ˆë‹¤ ëª…í™•í•œ ì£¼ì œ ë¬¸ì¥ê³¼ ì„±ê²½ì  ê·¼ê±°
   - í’ì„±í•œ ì˜ˆí™”ì™€ êµ¬ì²´ì ì¸ ì ìš©
   - ì²­ì¤‘ì´ ê³µê°í•  ìˆ˜ ìˆëŠ” ì‹¤ìƒí™œ ì—°ê²°
3. ê²°ë¡ :
   - í•µì‹¬ ë©”ì‹œì§€ ì¬ê°•ì¡°
   - êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ë„ì „
   - ì€í˜œë¡­ê³  í¬ë§ì ì¸ ë§ˆë¬´ë¦¬

âš ï¸ ì£¼ì˜ì‚¬í•­:
- miniì˜ ê°œìš”ë¥¼ ì°¸ê³ í•˜ë˜, ë¬¸ì¥ì€ ì²˜ìŒë¶€í„° ìƒˆë¡œ ì‘ì„±
- ì¶”ìƒì ì¸ í‘œí˜„ì„ í”¼í•˜ê³  êµ¬ì²´ì ì´ê³  ìƒìƒí•˜ê²Œ
- ìµœì†Œ 2000ì ì´ìƒ, ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±
- í•œêµ­ êµíšŒ ì²­ì¤‘ì´ ë“£ê¸°ì— ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©

ì§€ê¸ˆ ì‹œì‘í•˜ì„¸ìš”! í’ì„±í•˜ê³  ê°ë™ì ì¸ ì„¤êµë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        # GPT í˜¸ì¶œ (gpt-4o = GPT-5.1)
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ],
            temperature=0.8,
            max_tokens=8000  # ë” ê¸´ ì„¤êµë¬¸ì„ ìœ„í•´ í† í° ì¦ê°€
        )

        result = completion.choices[0].message.content.strip()

        print(f"[GPT-PRO] ì™„ë£Œ")

        return jsonify({"ok": True, "result": result})

    except Exception as e:
        print(f"[GPT-PRO][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Render ë°°í¬ë¥¼ ìœ„í•œ ì„¤ì • =====
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5058))
    app.run(host="0.0.0.0", port=port, debug=False)